{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8d0be90-e918-46b1-9dc3-aabd6136b1b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba5c02ab-6149-4fe1-89f1-a0b705779308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5d2f100-c61d-4d49-8abd-58b228807cab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: \n",
      "label      0\n",
      "review    35\n",
      "dtype: int64 \n",
      "\n",
      "Categories:  ['neg' 'pos'] \n",
      "\n",
      "Rate of each category: \n",
      "neg    1000\n",
      "pos    1000\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./TextFiles/moviereviews.tsv',sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "print('Missing values: ')\n",
    "print(df.isnull().sum(),'\\n')\n",
    "\n",
    "print('Categories: ',df['label'].unique(),'\\n')\n",
    "\n",
    "\n",
    "print('Rate of each category: ')\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf3ddee-7cfd-4ec4-9303-3321634f0d4c",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e83c3d-0571-42fb-8fda-85d420329517",
   "metadata": {},
   "source": [
    "#### Drop Missing Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33bd0c1c-4b88-42ac-ba81-95deb3b8d6e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: \n",
      "label     0\n",
      "review    0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "print('Missing values: ')\n",
    "print(df.isnull().sum(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d306365-97dd-4345-94e4-12e444404e6d",
   "metadata": {},
   "source": [
    "#### Finding Empty Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30982bb5-6bb0-4669-92db-101573493cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of empty reviews:  [57, 71, 147, 151, 283, 307, 313, 323, 343, 351, 427, 501, 633, 675, 815, 851, 977, 1079, 1299, 1455, 1493, 1525, 1531, 1763, 1851, 1905, 1993]\n"
     ]
    }
   ],
   "source": [
    "blanks=[]\n",
    "for i, lb, rv in df.itertuples():\n",
    "    if rv.isspace():\n",
    "        blanks.append(i)\n",
    "print('Index of empty reviews: ',blanks)\n",
    "df.drop(blanks,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7637e92-bd40-4288-9337-161f5a350440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   neg  how do films like mouse hunt get into theatres...\n",
       "1   neg  some talented actresses are blessed with a dem...\n",
       "2   pos  this has been an extraordinary year for austra...\n",
       "3   pos  according to hollywood movies made in last few...\n",
       "4   neg  my first press screening of 1998 and already i..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de439cec-a1e4-4465-8e6f-072a97012097",
   "metadata": {},
   "source": [
    "#### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23fd706c-979b-4758-bf3f-ae1e87abfe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba7268d-90ba-4fb0-89f1-2e48da004311",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba1c0fa3-810a-491d-b3d5-feeabd1d8a0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11561db1-4b7f-4ec7-b86e-b658b6fda429",
   "metadata": {},
   "source": [
    "#### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61011956-1432-4b70-8b12-502baf1d0970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016de4b1-64de-4df5-8abe-18a1a311a974",
   "metadata": {},
   "source": [
    "#### Shape of train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87e1f943-455d-4a83-ba9a-35f6e280d9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (1356,)\n",
      "test data shape: (582,)\n"
     ]
    }
   ],
   "source": [
    "print('train data shape:', X_train.shape)\n",
    "print('test data shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d0ff0-55ae-4421-81d9-f9a3fca0d781",
   "metadata": {},
   "source": [
    "## Classifier ML model pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2559fb7-3b90-44e6-9933-b749d9f419be",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dfaa6bb-2ba9-47ea-8289-cfb18c5290bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b2966-e303-42b2-bbac-29204e4d4d46",
   "metadata": {},
   "source": [
    "#### Confusion Matrix and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e5f84a5-dc2b-463d-9112-c5b71b1c48e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ham  spam\n",
      "ham   1370    81\n",
      "spam   104   117 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      0.94      0.94      1451\n",
      "        spam       0.59      0.53      0.56       221\n",
      "\n",
      "    accuracy                           0.89      1672\n",
      "   macro avg       0.76      0.74      0.75      1672\n",
      "weighted avg       0.88      0.89      0.89      1672\n",
      " \n",
      "\n",
      "Model accuracy:  88.93540669856459\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "df_conf_mat= pd.DataFrame(metrics.confusion_matrix(y_test, predictions), index=['ham','spam'], columns=['ham','spam'])\n",
    "print(df_conf_mat,'\\n')\n",
    "\n",
    "clf_report = metrics.classification_report(y_test, predictions)\n",
    "print(clf_report,'\\n')\n",
    "\n",
    "acc = metrics.accuracy_score(y_test,predictions)\n",
    "print('Model accuracy: ', acc*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
